"""
datatools.py - provides data management functions,
- load data
- generate polynomial bases and multi-wavelet (mw) details
- generate and apply quadrature
- preform mw-adaptivity
- save generated data

@author: kroeker
"""
import pandas as pd
import numpy as np
from scipy.linalg import lstsq
from . import polytools as pt
from . import utils as u
#from . import wavetools as wt

EPS = 1e-20 # epsilon

def genHankel(dataframe, srcs, nr_range, n_o):
    """ generates Hankel matrixes for each Nri, writes in h_dict """
    #Nr=max(NrRange)
    h_dict = {}

    for src in srcs:
        data = dataframe[src]
        for anr in nr_range:
            for nri in range(2**anr):
                l_b, r_b = cmp_lrb(anr, nri)
                qlb = data.quantile(l_b)
                qrb = data.quantile(r_b)
                mask = cmp_quant_domain(data, qlb, qrb)
                key = u.gen_dict_key(anr, nri, src)
                h_dict[key] = pt.Hankel(n_o+1, data[mask])
                #print(H)
    return h_dict

def genHankel_uniform(lb_v, ub_v, srcs, nr_range, n_o):
    """ generates Hankel matrixes for uniform distribution with
    Input:
        lb_v: list of lower bounds
        ub_v: list of upper bounds
        srcs: list of used sources
        nr_range: list of refinement levels NR
        n_o: polynomial degree

    Output:
        h_dict: dictionaly of Hankel matrices (np.array)
        """
    h_dict = {}
    for src in srcs:
        trans = lambda x: x*(ub_v[src] - lb_v[src]) + lb_v[src]
        for nr_a in nr_range:
            for nr_i in range(2**nr_a):
                lb_i, ub_i = cmp_lrb(nr_a, nr_i)
                lb_ir = trans(lb_i)
                ub_ir = trans(ub_i)
                key = u.gen_dict_key(nr_a, nr_i, src)
                h_dict[key] = pt.uniHank(n_o+1, lb_ir, ub_ir)
    return h_dict

def gen_nr_range_bds(dataframe, srcs, nr_range):
    """ generates dictionary with boundaries of MR-elements """
    nrb_dict = {}
    for src in srcs:
        data = dataframe[src]
        for anr in nr_range:
            for nri in range(2**anr):
                l_b, r_b = cmp_lrb(anr, nri)
                qlb = data.quantile(l_b)
                qrb = data.quantile(r_b)
                key = u.gen_dict_key(anr, nri, src)
                nrb_dict[key] = (qlb, qrb)
    return nrb_dict

def gen_nr_range_bds_4list(bds_list, srcs, nr_range):
    """ generates dictionary with boundaries of MR-elements """
    nrb_dict = {}
    for src in srcs:
        g_lb = bds_list[src][0]
        g_ub = bds_list[src][1]
        delta = g_ub - g_lb
        for anr in nr_range:
            for nri in range(2**anr):
                l_b, r_b = cmp_lrb(anr, nri)
                qlb = g_lb + l_b * delta
                qrb = g_lb + r_b * delta

                if nri == 0:
                    qlb -= EPS
                elif nri == 2**anr-1:
                    qrb += EPS
                key = u.gen_dict_key(anr, nri, src)
                nrb_dict[key] = (qlb, qrb)
    return nrb_dict

def get_nr_bds(nrb_dict, srcs, n_r):
    """
    get element boundaries for given refinement level n_r

    Parameters
    ----------
    nrb_dict : dictionary
        dictionary of all element bounds.
    srcs : list
        list of sournces, par ex. [0, 1, 2].
    n_r : integer
        refinement level.

    Returns
    -------
    dict_4_nr : dictionary
        dictionary of elem. bounds for ref, leevel n_r.

    """
    dict_4_nr = {}
    for src in srcs:
        for nri in range(2**n_r):
            key = u.gen_dict_key(n_r, nri, src)
            dict_4_nr[key] = nrb_dict[key]
    return dict_4_nr

def gen_roots_weights(h_dict, method, nr_bounds=None):
    """
    generates dictionaries with roots and weights
    generated by methods 0- Gautschi / 1-Karniadakis & Kirby
    """
    roots = {}
    weights = {}
    for key in h_dict:
        r, w = pt.gen_rw(h_dict[key], method)
        roots[key] = r
        if not nr_bounds is None:
            assert min(r) >= nr_bounds[key][0], "roots violate the lower boundary"
            assert max(r) <= nr_bounds[key][1], "roots violate the upper boudnary"
        weights[key] = w
    return roots, weights

def cmp_lrb(n_r, nri):
    """ computes left and right bounds for use in dataframe.quantile() """
    rcf = 2**(n_r)
    l_b = nri/rcf
    r_b = (nri+1)/rcf
    return l_b, r_b

def cmp_quant_domain(data, qlb, qrb):
    """ generates bool array with 1 for x in [qlb,qrb], 0 else """
    b_mask = (data >= qlb) & (data <= qrb)
    return b_mask

def cmp_mw_quant_domain(roots, nrb_dict, nrs, nris, cols):
    """
    generates bool array with 1 for r inside of
    [a_0,b_0]x..x[a_d,b_d], 0 else
    """
    n = roots.shape[0]
    ndim = len(nrs)
    assert ndim == len(nris)
    b_mask = np.ones(n, dtype=bool)
    for d, c in enumerate(cols):
        key = u.gen_dict_key(nrs[d], nris[d], c)
        qlb, qrb = nrb_dict[key]
        b_mask = b_mask & cmp_quant_domain(roots[c], qlb, qrb)
    return b_mask

def cmp_mv_quant_domain_mk(roots, nrb_dict, mkey):
    """
    generates bool array with 1 for r inside of
    [a_0,b_0]x..x[a_d,b_d], 0 else
    for given multikey mkey
    """
    n, sdim = roots.shape
    assert sdim == len(mkey)
    b_mask = np.ones(n, dtype=bool)
    for d in range(sdim):
        key = mkey[d]
        qlb, qrb = nrb_dict[key]
        b_mask = b_mask & cmp_quant_domain(roots[:, d], qlb, qrb)
    return b_mask

def gen_pcs(h_dict, method):
    """
    generated dictionaries with matrices of monic orthogonal
    polynomials, method 0: Gautschi style, 1: Sergey Style (aPC).
    """
    cfs = {}
    for key in h_dict:
        cfs[key] = pt.gen_pc_mx(h_dict[key], method)
    return cfs

def gen_npcs(pc_dict, roots, weights):
    """ generates dictionary with coeficients of orthonormal polynomials """
    n_cfs = {}
    for key in pc_dict:
        n_cfs[key] = pt.gen_npc_mx(pc_dict[key], roots[key], weights[key])
    return n_cfs

def gen_npcs_mm(pc_dict, H_dict):
    """
    generates normed polynomal coefficients using moment matrix (Hankel matrix)

    Parameters
    ----------
    pc_dict : dictionary
        pol. coeficients of monic orthogonal polynomials.
    H_dict : dictionary
        Hankel (moment) matrixes.

    Returns
    -------
    n_cfs : dictionary
        normed polynomial coefficients (orthonormal polynomials).

    """
    n_cfs = {}
    for key in pc_dict:
        n_cfs[key] = pt.gen_npc_mx_mm(pc_dict[key], H_dict[key])
    return n_cfs

def pcfs4eval(pc_dict, mkey, alpha):
    """ provides PC-Cfs for multi-polynomial with degrees in alpha """
    mdeg = max(alpha)
    alen = len(alpha)
    assert alen == len(mkey)
    rcfs = np.zeros((alen, mdeg+1))
    for d in range(alen):
        ad = alpha[d]
        cfs = pc_dict[mkey[d]]
        rcfs[d, :] = cfs[ad, 0:mdeg+1]
    return rcfs

def Gauss_quad(func, roots, weights):
    """ Gauss quadrature with roots and weights """
    assert len(roots) == len(weights)
    return np.inner(func(roots), weights)

def inner_prod(f_la, g_la, roots, weights):
    """ inner product <f,g,>, computed by Gauss quadrature """
    return Gauss_quad(lambda x: f_la(x)*g_la(x), roots, weights)

def Gauss_quad_idx(fct, multi_key, roots, weights):
    """ multi-dimensional Gauss quad on multiKey of
    f_0(x_0)*...*f_dim-1(x_dim-1), Func=(f_0,...,f_dim-1)
    """
    dim = len(multi_key)
    r_mk, w_mk = gen_rw_4mkey(multi_key, roots, weights)
    if isinstance(fct, tuple):
        assert dim == len(fct)
        ret = Gauss_quad_arr(fct, r_mk, w_mk)
    else:
        ret = Gauss_quad_fct(fct, r_mk, w_mk)
    return ret

def inner_prod_multi_idx(fkt_f, fkt_g, multi_key, roots, weights):
    """ <F,G>, for for multi-index multiKey """
    dim = len(multi_key)
    r_mk, w_mk = gen_rw_4mkey(multi_key, roots, weights)
    assert type(fkt_f) == type(fkt_g)
    t_f = isinstance(fkt_f, tuple)
    t_g = isinstance(fkt_g, tuple)
    if t_f and t_g:
        flen = len(fkt_f)
        assert flen == len(fkt_g)
        assert flen == dim
        ret = inner_prod_tuples(fkt_f, fkt_g, r_mk, w_mk)
    else:
        ret = inner_prod_fct(fkt_f, fkt_g, r_mk, w_mk)
    return ret

def Gauss_quad_arr(fct_tup, roots, weights):
    """
    Gauss quadrature for function touple and arrays of roots-n-weights

    Parameters
    ----------
    fct_tup : touple of length d
        touple of d-functions.
    roots : np.array
        d-dimensional array of roots (eval. points).
    weights : np.array
        d-dimensional array of weights (related to roots).

    Returns
    -------
    S : float
        result of Gaussian quadrature.

    """
    dim = len(fct_tup)
    evals = roots.shape[0]
    t_a = dim == roots.shape[1]
    t_b = roots.size == weights.size
    assert t_a and t_b
    S = 0
    for l in range(evals):
        tmp = 1
        for d in range(dim):
            key = (l, d)
            tmp = tmp*fct_tup[d](roots[key])*weights[key]
        S += tmp
    return S

def inner_prod_tuples(F, G, roots, weights):
    """ <F,G>, F,G are given by tuples """
    dim = len(F)
    evals = roots.shape[0]
    a = dim == len(G)
    b = roots.size == weights.size
    c = dim == roots.shape[1]
    assert a and b and c
    S = 0
    for l in range(evals):
        tmp = 1
        for d in range(dim):
            key = (l, d)
            x = roots[key]
            tmp = tmp*F[d](x)*G[d](x)*weights[key]
        S += tmp
    return S

def Gauss_quad_fct(fct, roots, weights):
    """ computes Gauss quadratur of the function fct on roots-n-weights"""
    assert roots.shape == weights.shape
    arr = fct(roots)*weights
    return sum(np.prod(arr, axis=1))


def inner_prod_fct(f_la, g_la, roots, weights):
    """ <f_la, g_la> on roots-n-weights, for lambdas f_la, and g_la """
    assert roots.shape == weights.shape
    quad_arr = f_la(roots)*g_la(roots)*weights
    return sum(np.prod(quad_arr, axis=1))


def inner_prod_arr_fct(arr, f_la, roots, weights, srcs):
    """ inner product of data in Arr and F(Roots) weighted with Weigths """
    assert roots.shape == weights.shape
    quad_arr = f_la(roots[srcs])*weights[srcs]
    prod_arr = np.prod(quad_arr, axis=1)
    return np.inner(arr, prod_arr)


def gen_rw_4mkey(mkey, roots, weights):
    """ generates roots and weights arrays from dict's Roots and Weights for multikey mkey """
    cols = len(mkey)
    # ls=[]
    # for d in range(cols):
    #     key=mKey[d]
    #     #print("k->r",key,Roots[key])
    #     lk=len(Roots[key])
    #     ls.append(lk)
    ls = [len(roots[key]) for key in mkey]
    lens = np.array(ls)
    lines = lens.prod()
    I = u.midx4quad(lens)
    r_roots = np.zeros((lines, cols))
    r_weights = np.zeros([lines, cols])
    for c in range(cols):
        key = mkey[c]
        r = roots[key]
        w = weights[key]
        idx = I[:, c]
        #print(idx,r)

        r_roots[:, c] = r[idx]
        r_weights[:, c] = w[I[:, c]]
    return r_roots, r_weights

def get_rw_4mkey(mkLst, roots, weights):
    """ generates eval. points and weights  np.arrays and
    (point number)->mkey list   for multi-keys in mkArr list """
    #tcnt=len(mkLst)
    R = np.array([])
    W = np.array([])
    mk_lst_long = [] #  multi-key in order of apperance
    points4mk = 0
    for mkey in mkLst:
        r, w = gen_rw_4mkey(mkey, roots, weights)
        points4mk = len(r)
        mk_lst_long = mk_lst_long+[mkey for c in range(points4mk)]
        if R.size == 0:
            R = r
            W = w
        else:
            R = np.concatenate([R, r], axis=0)
            W = np.concatenate([W, w], axis=0)
    return R, W, mk_lst_long

def get_rw_4nrs(nrs, srcs, roots, weights):
    """ generates eval. points and weights for a Nr level """
    dim = len(nrs)
    nris = np.zeros(dim)
    nri_cnt = np.zeros(dim, dtype=int)
    divs = np.zeros(dim)
    R = np.array([])
    W = np.array([])
    mk_lst_long = [] #  multi-key in order of apperance

    for d in range(dim):
        #aNr = Nrs[d]
        nri_cnt[d] = 2**nrs[d]
        divs[d] = np.prod(nri_cnt[0:d])

    tnri_cnt = np.prod(nri_cnt)
    for l in range(tnri_cnt):
        for d in range(dim):
            nris[d] = (l//divs[d] % nri_cnt[d])
        mkey = u.gen_multi_key(nrs, nris, srcs)
        r, w = gen_rw_4mkey(mkey, roots, weights)
        #r=np.reshape(r,(-1,dim))
        mk_lst_long = mk_lst_long+[mkey for c in range(len(r))]
        if R.size == 0:
            R = r
            W = w
        else:
            R = np.concatenate([R, r], axis=0)
            W = np.concatenate([W, w], axis=0)
    return R, W, mk_lst_long

def gen_quant_dict(dataframe, srcs, nr_range, wvt):
    """
    generates dictionary of quantiles on roots for each Nri and Nr in NrRange
    accorting to roots stored in already initialized object of wavetools wt
    using data in dataframe for columns in srcs
    """
    q_dict = {}

    for src in srcs:
        data = dataframe[src]
        for anr in nr_range:
            for nri in range(2**anr):
                quants = wvt.cmp_data_on_roots(data, anr, nri)
                key = u.gen_dict_key(anr, nri, src)
                q_dict[key] = quants
    return q_dict

def gen_detail_dict(q_dict, wvt, dicts=0):
    """
    generates dictionary of Details on roots for each set of quantiles
    stored in Qdict, using initalized wavetool wvt
    dits=0: sum(abs(details)), 1: lDetails only, 2 both
    """
    det_dict = {}
    ldet_dict = {}
    s = dicts in (0, 2)
    l = dicts >= 1
    for key, data in q_dict.items():
        #Nr=key[u.ParPos['Nr']]
        ldetails = wvt.cmp_details(data)
        if l:
            ldet_dict[key] = ldetails
        if s:
            det_dict[key] = sum(abs(ldetails))
    if dicts == 0:
        ret = det_dict
    elif dicts == 1:
        ret = ldet_dict
    else:
        return  det_dict, ldet_dict
    return ret

def mark_dict4keep(d_dict, thres):
    """ marks the details>= threshold for keep """
    k_dict = {}
    for key, data in d_dict.items():
        b = data >= thres
        k_dict[key] = b
    return k_dict

def get_true_nodes(k_dict, key):
    """
    checks leafs of the tree bottom ab, leafs only highest "True"-level on True
    """
    ret = 0
    if k_dict[key]:
        ret = 1

    nri = key[u.ParPos['Nri']]
    nr = key[u.ParPos['Nr']]
    src = key[u.ParPos['src']]
    lnri = 2*nri # left kid
    rnri = lnri+1 # right kid
    lkey = u.gen_dict_key(nr+1, lnri, src)
    rkey = u.gen_dict_key(nr+1, rnri, src)
    lex = lkey in k_dict.keys()
    rex = rkey in k_dict.keys()
    if lex and rex:
        l = get_true_nodes(k_dict, lkey)
        r = get_true_nodes(k_dict, rkey)
        kids = l + r
        if kids > 0:
            k_dict[key] = False
            if  l == 0:
                k_dict[lkey] = True
                ret += 1
            if  r == 0:
                k_dict[rkey] = True
                ret += 1
                ret += kids
    return ret

def get_top_keys(k_dict, srcs):
    """ returns set with top level (True) keys only (bottom up)"""
    t_keys = k_dict.copy()
    for src in srcs:
        root_key = u.gen_dict_key(0, 0, src) #multi-key on zero-level (root)
        if root_key in t_keys.keys():
            cnt = get_true_nodes(t_keys, root_key)
            if cnt == 0:
                t_keys[root_key] = True # set root node to True if no leafs are selected
    return t_keys

def gen_mkey_list(k_dict, srcs):
    """ generates array of multi-keys from the dictionary Kdict """
    isrcs = u.inv_src_arr(srcs)
    k_lst = [[] for s in isrcs]
    srclen = len(isrcs)
    sidx = u.ParPos['src']
    for key, chk in k_dict.items():
        if chk:
            idx = key[sidx]
            k_lst[isrcs[idx]].append(key)
    alen = [len(c) for c in k_lst]
    I = u.midx4quad(alen)
    ilen, _ = np.shape(I)
    # required also for 1-dim case, to generate multikey -> tuple(tuple)
    return [tuple([k_lst[c][I[i, c]] for c in range(srclen)]) for i in range(ilen)]


def gen_mkey_sid_rel(samples, mk_lst, nrb_dict):
    """
    generates long sample->[multi-key ]
    multi-key -> np.array([sample id]) dictionaries

    return : sid2mk, mk2sids
    """
    sample_cnt, _ = samples.shape
    sids = np.arange(sample_cnt)
    sid2mk = {}
    mk2sids = {}
    for mkey in mk_lst:
        B = cmp_mv_quant_domain_mk(samples, nrb_dict, mkey)
        if B.sum() > 0:
            mk2sids[mkey] = sids[B]
            for sid in mk2sids[mkey]:
                if sid in sid2mk:
                    sid2mk[sid] += mkey
                else:
                    sid2mk[sid] = [mkey]
    return sid2mk, mk2sids

def sample2mkey(sample, mk_lst, nrb_dict, find_all_mkeys=False):
    """ finds first, all multi-key in NR-Bounds dictrionary corresponding to the
    multi-element containing the sample
    """
    ndim = len(sample)
    smk_list = []
    for mkey in mk_lst:
        chk = True
        for d in range(ndim):
            qlb, qrb = nrb_dict[mkey[d]]
            chk = chk & cmp_quant_domain(sample[d], qlb, qrb)
        if chk:
            if find_all_mkeys:
                smk_list += [mkey]
            else:
                smk_list = [mkey]
    return smk_list

def cmp_resc_cfl(anr_list):
    """
    computes rescaling cfs c=<phi^Nr_l,0,phi^0_0,0>.
    Is relevant for computing Exp. / Var. from coefficients only
    for aNRlist [aNr_0,...,aNr_d]
    """
    cft = 1
    for anr in anr_list:
        cft /= 2**(anr)
    return cft

def cmp_resc_cf(mkey):
    """
    computes rescaling coeficients c=<phi^Nr_l,0,phi^0_0,0>.
    Is relevant for computing Exp. / Var. from coefficients only
    for multi-key mKey
    """
    dim = len(mkey)
    nr_pos = u.ParPos['aNr']
    cft = 1
    for d in range(dim):
        key = mkey[d]
        cft /= 2**(key[nr_pos])
    return cft

def gen_rcf_dict(mk_list):
    """
    Generates dictionary with rescaling coefficients for ech
    multi-key in mkList [(mk),...]
    """
    rcf_dict = {}
    for mkey in mk_list:
        rcf_dict[mkey] = cmp_resc_cf(mkey)
    return rcf_dict

def gen_phi(mkey, pol_vals, mk2sid, alpha_dict=None):
    sids = mk2sid[mkey]
    if alpha_dict is None or mkey not in alpha_dict:
        phi = (pol_vals[:, sids][:, :]).T
    else:
        phi = (pol_vals[:, sids][alpha_dict[mkey], :]).T
    return phi

def gen_cov_mx_4lh(phi, s_sigma_n, s_sigma_p):
    """
    generates covariance etc. matrixes for likelihood

    Parameters
    ----------
    phi: np.array, [sid, p] pol vals
    s_sigma_n : float,  var noise ~ Q
    s_sigma_p : float, var prioir ~ R

    Returns
    --------
    cov_mx_inv inverse cov. matrix
    """
#    if s_sigma_n < 1e-42 or s_sigma_p < 1e-42:
#        print("sigma n/p", s_sigma_n, s_sigma_p)
#        return np.nan, np.nan
    Q = np.eye(phi.shape[0]) * s_sigma_n
    R = np.eye(phi.shape[1]) * s_sigma_p
    Q_inv = np.eye(phi.shape[0]) / s_sigma_n
    R_inv = np.eye(phi.shape[1]) / s_sigma_p
    P = phi.T @ Q_inv @ phi + R_inv

    try:
        if  np.multiply.reduce(np.diag(np.linalg.cholesky(P)))> 0:
            P_inv = np.linalg.pinv(P)
            # inverse according to eq. (A.9) in Rasmussen and Williams
            cov_mx_inv = Q_inv - Q_inv @ phi @ P_inv @ phi.T @ Q_inv
        else:
            cov_mx_inv = np.nan
    except (RuntimeError, ValueError):
        cov_mx_inv = np.nan

    cov_mx = phi @ R @ phi.T + Q
    return cov_mx, cov_mx_inv

def sample_amrpc_rec(samples, mk_list, alphas, f_cfs, f_cov_mx,
                     npc_dict, nrb_dict,
                     mk2sid, alpha_masks=None, **kwargs):
    """
    Generates function reconstruction
    f(sample, x) = sum_(p in alphas) f_cfs(sample_mk, p,  x) * pol(alpha_p, sample)

    Parameters
    ----------
    samples : np.array
        samples/input parameters for evaluation, samples[i] = [s_0, s_1, ..., s_n].
    mk_list : list of tuples
        (unique) list of multi-keys ((key,0),...,(key, n)).
    alphas : np.array
        matrix of multi-indexes representing pol. degrees of multi-variate polynomials.
    f_cfs : np.array
        reconstr. coefficients f_cfs[sample,alpha_p,idx_x].
    f_cov_mx : np.array
        reconstr. cov_matrices f_cov_mx[sample,alpha_p, alpha_p,idx_x].
    npc_dict : dict
        dictionary of normed piecewise polynomials.
    nrb_dict : dict
        dictionary of stochastic-element boundaries.
    mk2sid : dict
        (multi key) -> sample id dictionary.
    alpha_masks: dict
        (multi key) -> mask for alphas, such that only true degrees were used
    kwargs.n_samples_out: int default 1
        number of samples for each input parameter combination in samples
    Returns
    -------
    f_rec : np.array
        amrpc reconstruction of the function f, f_rec[sample_out, sample_id, idx_x].

    """
    n_s = samples.shape[0]
    n_x = f_cfs.shape[2]
    n_so = kwargs.get('n_samples_out', 1)
    f_rec = np.zeros((n_so, n_s, n_x))
    key = "mk2sid_samples"
    mk2sid_loc = kwargs.get(key, gen_mkey_sid_rel(samples, mk_list, nrb_dict)[1])
    key = 'p_vals'
    p_vals = kwargs.get(key, gen_pol_on_samples_arr(samples, npc_dict, alphas, mk2sid_loc))
    rng = np.random.default_rng()
    idxs_p = np.arange(alphas.shape[0])

    for mkey, sids_l in mk2sid_loc.items():
        sids = mk2sid[mkey]
        if alpha_masks is not None and len(alpha_masks) != 0:
            idxs_pm = idxs_p[alpha_masks[mkey]]
            alpha_mask = alpha_masks[mkey]
        else:
            idxs_pm = idxs_p
            alpha_mask = np.ones(alphas.shape[0], dtype=bool)
#        cov_pmask = np.multiply.outer(alpha_mask, alpha_mask)
        if len(f_cov_mx.shape) < 4:
            f_cov_mx = np.expand_dims(f_cov_mx, 0)
#        phi_all = p_vals[idxs_pm, :]
#        phi = phi_all[:, sids_l].T
        phi = (p_vals[:, sids_l][idxs_pm, :]).T
        for idx_x in range(n_x):
#            for sid_l in sids_l:
#                f_rec[:, sid_l, idx_x] = f_cfs_s @ p_vals[idxs_pm, sid_l]

            f_cfs_s = rng.multivariate_normal(phi @ f_cfs[sids[0], alpha_mask, idx_x],
                                              phi @ f_cov_mx[sids[0], alpha_mask, :, idx_x][:, alpha_mask] @ phi.T,
                                              n_so)
            #for sid_l in sids_l:
            f_rec[:, sids_l, idx_x] = f_cfs_s

    return f_rec

def gen_amrpc_rec(samples, mk_list, alphas, f_cfs, npc_dict, nrb_dict,
                  mk2sid, alpha_masks=None, **kwargs):
    """
    Generates function reconstruction
    f(sample, x) = sum_(p in alphas) f_cfs(sample_mk, p,  x) * pol(alpha_p, sample)

    Parameters
    ----------
    samples : np.array
        samples for evaluation, samples[i] = [s_0, s_1, ..., s_n].
    mk_list : list of tuples
        (unique) list of multi-keys ((key,0),...,(key, n)).
    alphas : np.array
        matrix of multi-indexes representing pol. degrees of multi-variate polynomials.
    f_cfs : np.array
        reconstr. coefficients f_cfs[sample_mkey,alpha_p,idx_x]
        or f_cfs[sample_cf, sample_mkey, ,alpha_p,idx_x].
    npc_dict : dict
        dictionary of normed piecewise polynomials.
    nrb_dict : dict
        dictionary of stochastic-element boundaries.
    mk2sid : dict
        (multi key) -> sample id dictionary.
    alpha_masks: dict
        (multi key) -> mask for alphas, such that only true degrees were used


    Returns
    -------
    f_rec : np.array
        ampc reconstruction of the function f, f_rec[sample_id, idx_x].

    """
    n_s = samples.shape[0]
    if isinstance(f_cfs, dict):
        mkey_type = True
        f_n_tuple = f_cfs[next(iter(f_cfs))].shape
        if len(f_n_tuple) > 2:
            n_so = f_n_tuple[0]
            n_x = f_n_tuple[2]
            f_rec = np.zeros((n_so, n_s, n_x))
        else:
            n_x = f_n_tuple[1]
            n_so = 0
            f_rec = np.zeros((n_s, n_x))
        
    else:
        mkey_type = False
        f_n_tuple = f_cfs.shape

        if len(f_n_tuple) > 3:
            n_so = f_n_tuple[0]
            n_x = f_n_tuple[3]
            f_rec = np.zeros((n_so, n_s, n_x))
        else:
            n_x = f_n_tuple[2]
            n_so = 0
            f_rec = np.zeros((n_s, n_x))



    key = "mk2sid_samples"
    mk2sid_loc = kwargs.get(key, gen_mkey_sid_rel(samples, mk_list, nrb_dict)[1])
    key = 'p_vals'
    p_vals = kwargs.get(key, gen_pol_on_samples_arr(samples, npc_dict, alphas, mk2sid_loc))

    idxs_p = np.arange(alphas.shape[0])
    for mkey, sids_l in mk2sid_loc.items():
        sids = mk2sid[mkey]
        if alpha_masks is not None and len(alpha_masks) != 0:
            idxs_pm = idxs_p[alpha_masks[mkey]]
        else:
            idxs_pm = idxs_p

#        phi_all = p_vals[idxs_pm, :]
#        f_rec[sids_l, :] = phi_all[:, sids_l].T @ f_cfs[sids[0], idxs_pm, :]
        #phi = gen_phi(mkey, p_vals, mk2sid_loc, alpha_masks)
        phi = (p_vals[:, sids_l][idxs_pm, :]).T
        if mkey_type:
            if n_so > 0:
                for idx_x in range(n_x):
                    f_rec[:, sids_l, idx_x] = (phi @ f_cfs[mkey][:, idxs_pm, idx_x].T).T
            else:
                f_rec[sids_l, :] = phi @ f_cfs[mkey][:, idxs_pm]
        else:
            if n_so > 0:
                for idx_x in range(n_x):
                    f_rec[:, sids_l, idx_x] = (phi @ f_cfs[:, sids[0], idxs_pm, idx_x].T).T
            else:
                f_rec[sids_l, :] = phi @ f_cfs[sids[0], idxs_pm, :]
#        for sid_l in sids_l:
#            f_rec[sid_l, :] = f_cfs[sids[0], idxs_pm, :].T @ p_vals[idxs_pm, sid_l]

    return f_rec

def gen_pol_on_samples_arr(samples, npc_dict, alphas, mk2sid):
    """
    generates np.array with pol. vals for each sample and pol. degree
    samples : samples for evaluation (evtl. samples[srcs] )
    nPCdict: pol. coeff. dictionary
    Alphas: matrix of multiindexes representing pol. degrees
    mk2sid: multi-key -> sample id's (sid lists should be disjoint)
    return: pol_vals[sample id] = [pol_i:p_i(x_0),...p_i(x_end)]
    """
    n_s, _ = samples.shape
    p_max = alphas.shape[0]
    pol_vals = np.zeros((p_max, n_s))

    for mkey, sids in mk2sid.items():
        for idx_p in range(p_max):
            pcfs = pcfs4eval(npc_dict, mkey, alphas[idx_p])
            pvals = pt.pc_eval(pcfs, samples[sids, :])
            pol_vals[idx_p, sids] = np.prod(pvals, axis=1)
    return pol_vals

def sample_amprc_cfs(mk_list, alphas, f_cfs, f_cov_mx,
                     mk2sid, alpha_masks=None, **kwargs):
    """
    samples the polynomial-coeficients f_cfs(sample_mk, p, x) for
    f(sample, x) = sum_(p in alphas) f_cfs(sample_mk, p,  x) * pol(alpha_p, sample)
        Parameters
    ----------
    mk_list : list of tuples
        (unique) list of multi-keys ((key,0),...,(key, n)).
    alphas : np.array
        matrix of multi-indexes representing pol. degrees of multi-variate polynomials.
    f_cfs : np.array
        reconstr. coefficients f_cfs[sample,alpha_p,idx_x].
    f_cov_mx : np.array
        reconstr. cov_matrices f_cov_mx[sample,alpha_p, alpha_p,idx_x].
    mk2sid : dict
        (multi key) -> sample id dictionary.
    alpha_masks: dict
        (multi key) -> mask for alphas, such that only true degrees were used
    kwargs:
        n_samples_out: int default 1
            number of samples for each input parameter combination in samples
        x_start: integer
            first space_point_nr to eval.
        x_len: integer
            length of the x-vector to eval, default x_len=-1 -> all.
        mkey_out: bool, default False
            switchs to mkey-wise return if True
    Returns
    -------
    f_cfs : np.array or dictionary of np.arrays
        amrpc coeficients f, f_cfs[sample_out, sample_id, alpha_p, idx_x].
        aMR-PC coefficients f, f_cfs[mkey] -> [sample_out, alpha_p, idx_x]
    """
    n_tup = f_cfs.shape
    if len(n_tup) > 2:
        n_x = n_tup[2]
    else:
        n_x = 1
    n_so = kwargs.get('n_samples_out', 1)
    n_p = n_tup[1]
    n_s = n_tup[0]
    mkey_out = kwargs.get('mkey_out', False)
    x_start = kwargs.get('x_start', 0)
    x_len = kwargs.get("x_len", n_x)
    x_len = n_x if x_len < 0 else x_len
    if mkey_out:
        ret_f_cfs = {}
    else:
        ret_f_cfs = np.zeros((n_so, n_s, n_p, n_x))
    rng = np.random.default_rng()
    #idxs_p = np.arange(n_p)
    for mkey in mk_list:
        sids = mk2sid[mkey]
        if mkey_out:
            ret_f_cfs[mkey] = np.zeros((n_so, n_p, n_x))
        if alpha_masks is not None and len(alpha_masks) != 0:
            alpha_mask = alpha_masks[mkey]
        else:
            alpha_mask = np.ones(alphas.shape[0], dtype=bool)

        for idx_x in range(x_len):
            dt_idx_x = x_start + idx_x
            s_cfs = rng.multivariate_normal(f_cfs[sids[0], alpha_mask, dt_idx_x],
                                            f_cov_mx[sids[0], alpha_mask, :, dt_idx_x][:, alpha_mask],
                                            n_so)
            #print(s_cfs.shape)

            if mkey_out:
                ret_f_cfs[mkey][:, alpha_mask, idx_x] = s_cfs
            else:
                for sid in sids:
                    ret_f_cfs[:, sid, alpha_mask, idx_x] = s_cfs

    return ret_f_cfs

def gen_amrpc_dec_ls(data, pol_vals, mk2sid, **kwargs):
    """
    computes the armpc-decomposition coefficients f_p of
    f(x,theta) = sum_p f_p(x) * pol_p(sample)
    on each sample, (sid, p, x) by (pseudo inverse) least-squares

    Parameters
    ----------
    data : np.array[sample_id, space_point_nr]
        evaluations of f on samples theta for each space point x
    pol_vals : np.array[sample_id, pol_degree]
        eval of piecevise polynomials for each sample_id and pol_degree.
    mk2sid : dictionary
        MR-related multi-key -> sample id.
    kwargs:
        x_start: integer
            first space_point_nr to eval.
        x_len: integer
            length of the x-vector to eval, default x_len=-1
        method :   'pinv', 'pinvt', 'pinvth', 'ls', 'reg_n', 'reg_t'
            switches between least-squares and psedo-inverse based lsq
        sigma_n : sigma_noise, LS-weighting parameter
        sigma_p : sigma_prior  parameter for Tikhonov / ridge regularization
                    parameter for 'reg'
        return_std: bool, default=False, returns std-of the coeffs. for reg_t
        return_cov: bool, default=False, returns cov-mx of the coeffs. for reg_t
    Returns
    -------
    cf_ls_4s: np.array of f_i for [sid, p, x_i]
    [ret_std_cf or ret_cov_cf] depending on return_std or return_cov: np.array
    for [sid, p, x_i] or [sid, p, p, x_i]

    """
    # compute function coefficients by least-squares
    # Fct coefs on each sample, (sid, p, x): by LS
    n_tup = data.shape
    if len(n_tup) > 1:
        n_x = n_tup[1]
    else:
        n_x = 1

    x_start = kwargs.get('x_start', 0)
    x_len = kwargs.get("x_len", n_x)
    x_len = n_x if x_len < 0 else x_len
    method = kwargs.get("method", 'pinv')
    if method in ('reg_n', 'reg_t'):
        sigma_n = kwargs.get('sigma_n', 1e-5)
        sigma_p = kwargs.get('sigma_p', 1.0)
    assert x_start + x_len <= n_x
    n_s = n_tup[0]
    p_max = pol_vals.shape[0]
    cf_ls_4s = np.zeros((n_s, p_max, x_len))
    ret_std = kwargs.get('return_std', False)
    ret_cov = kwargs.get('return_cov', False)
    if ret_std:
        ret_std_cov_4s = np.zeros((n_s, p_max, x_len))
    elif ret_cov:
        ret_std_cov_4s = np.zeros((n_s, p_max, p_max, x_len))
    for mkey, sids in mk2sid.items():
        phi = pol_vals[:, sids].T
        if method in ('reg_n', 'reg_t'):
            if isinstance(sigma_n, dict):
                sigma_n_mk = sigma_n[mkey]**2
            elif isinstance(sigma_n, float):
                sigma_n_mk = sigma_n**2
            if isinstance(sigma_p, dict):
                sigma_p_mk = sigma_p[mkey]**2
            elif isinstance(sigma_p, float):
                sigma_p_mk = sigma_p**2
        for idx_x in range(x_len):
            # v, resid, rank, sigma = linalg.lstsq(A,y)
            # solves Av = y using least squares
            # sigma - singular values of A
            dt_idx_x = x_start + idx_x
            if n_s > 1:
                if method == 'pinv':
                    v_ls = np.linalg.pinv(phi) @ data[sids, dt_idx_x]
                elif method == 'pinvt':
                    v_ls = np.linalg.pinv(phi.T @ phi) @ phi.T @ data[sids, dt_idx_x]
                elif method == 'pinvth':
                    v_ls = (np.linalg.pinv(phi.T @ phi, hermitian=True)
                            @ phi.T @ data[sids, dt_idx_x])
                elif method == 'reg_n':
                    v_ls = (np.linalg.pinv(1/sigma_n_mk * phi.T @ phi) @ phi.T / sigma_n_mk
                            @ data[sids, dt_idx_x])
                elif method == 'reg_t':
                    P_inv = np.linalg.pinv((phi.T / sigma_n_mk) @ phi
                                           + np.eye(phi.shape[1]) / sigma_p_mk)
                    v_ls = (P_inv @ phi.T / sigma_n_mk @ data[sids, dt_idx_x])
                    if ret_std:
                        ret_std_cov_4s[sids, :, idx_x] = np.sqrt(np.diag(P_inv))
                    elif ret_cov:
                        ret_std_cov_4s[sids, :, :, idx_x] = P_inv
                else:
                    #v_ls, resid, rank, sigma = np.linalg.lstsq(
                    #    Phi, data[sids, idx_x], rcond=None) # LS - output
                    v_ls, _, _, _ = lstsq(
                        phi, data[sids, dt_idx_x]) # LS - output
    #                v_ls, _, _, _ = np.linalg.lstsq(
    #                    phi, data[sids, dt_idx_x], rcond=None) # LS - output
            else:
                v_ls = data[dt_idx_x]/phi
            cf_ls_4s[sids, :, idx_x] = v_ls
    return (cf_ls_4s, ret_std_cov_4s) if ret_std or ret_cov else cf_ls_4s

def gen_amrpc_dec_ls_mask(data, pol_vals, mk2sid, mask_dict, **kwargs):
    """
    computes the armpc-decomposition coefficients f_p of
    f(x,theta) = sum_p f_p(x) * pol_p(sample)
    on each sample, (sid, p, x) by (pseudo-inverse) least-squares

    Parameters
    ----------
    data : np.array[sample_id, space_point_nr]
        evaluations of f on samples theta for each space point x
    pol_vals : np.array[sample_id, pol_degree]
        eval of piecevise polynomials for each sample_id and pol_degree.
    mk2sid : dictionary
        MR-related multi-key -> sample id.
    mask_dict : dictionary
        MR-related multi-key -> numpy mask for used pc coefficients.
    kwargs:
        x_start: integer
            first space_point_nr to eval.
        x_len: integer
            length of the x-vector to eval, default x_len=-1 -> all.
        method :   'pinv', 'pinvt', 'pinvth', 'ls', 'reg_n', 'reg_t'
            switches between least-squares and psedo-inverse based lsq
        sigma_n : sigma_noise, LS-weighting parameter
        sigma_p : sigma_prior  parameter for Tikhonov / ridge regularization
                    parameter for 'reg'
        return_std: bool, default=False, returns std-of the coeffs. for reg_t
        return_cov: bool, default=False, returns cov-mx of the coeffs. for reg_t
    Returns
    -------
    ret_cf_ls_4s: np.array of f_i for [sid, p, x_i]
    [ret_std_cf or ret_cov_cf] depending on return_std or return_cov: np.array
    for [sid, p, x_i] or [sid, p, p, x_i]

    """
    # compute function coefficients by least-squares
    # Fct coefs on each sample, (sid, p, x): by LS
    n_tup = data.shape
    if len(n_tup) > 1:
        n_x = n_tup[1]
    else:
        n_x = 1
        data = data.reshape((n_tup[0], n_x))
    x_start = kwargs.get('x_start', 0)
    x_len = kwargs.get("x_len", n_x)
    x_len = n_x if x_len < 0 else x_len
    method = kwargs.get("method", 'pinv')
    #if method in ('reg_n', 'reg_t'):
    sigma_n = kwargs.get('sigma_n', 1e-10)
    sigma_p = kwargs.get('sigma_p', 1.0)
    assert x_start + x_len <= n_x
    n_s = n_tup[0]
    p_max = pol_vals.shape[0]
    ret_cf_ls_4s = np.zeros((n_s, p_max, x_len))
    ret_std = kwargs.get('return_std', False)
    ret_cov = kwargs.get('return_cov', False)
    if ret_std:
        ret_std_cov_4s = np.zeros((n_s, p_max, x_len))
    elif ret_cov:
        ret_std_cov_4s = np.zeros((n_s, p_max, p_max, x_len))

    for mkey, sids in mk2sid.items():
        alpha_mask = mask_dict[mkey]
#        phi = (pol_vals[:, sids][alpha_mask, :]).T
        phi = gen_phi(mkey, pol_vals, mk2sid, mask_dict)
        if isinstance(sigma_n, dict):
            sigma_n_mk = sigma_n[mkey]**2
        elif isinstance(sigma_n, float):
            sigma_n_mk = sigma_n**2
        if isinstance(sigma_p, dict):
            sigma_p_mk = sigma_p[mkey]**2
        elif isinstance(sigma_p, float):
            sigma_p_mk = sigma_p**2
        for idx_x in range(x_len):
            # v, resid, rank, sigma = linalg.lstsq(A,y)
            # solves Av = y using least squares
            # sigma - singular values of A
            dt_idx_x = x_start + idx_x
            if n_s > 1:
                if method == 'pinv':
                    v_ls = np.linalg.pinv(phi) @ data[sids, dt_idx_x]
                elif method == 'unbias':
                    v_ls = np.linalg.pinv(phi.T @ phi) @ phi.T @ data[sids, dt_idx_x]
                elif method == 'unbias_herm':
                    v_ls = (np.linalg.pinv(phi.T @ phi, hermitian=True)
                            @ phi.T @ data[sids, dt_idx_x])
                elif method == 'reg_n':
                    cov_op = np.linalg.pinv(1/sigma_n_mk * phi.T @ phi)
                    v_ls = (cov_op @ phi.T / sigma_n_mk
                            @ data[sids, dt_idx_x])
                    if ret_std:
                        ret_std_cov_4s[sids, :, idx_x] = np.sqrt(np.diag(cov_op))
                    elif ret_cov:
                        ret_std_cov_4s[sids, :, :, idx_x] = cov_op

                elif method == 'reg_t':
                    P_inv = (np.linalg.pinv((phi.T / sigma_n_mk) @ phi
                                            + np.eye(phi.shape[1]) / sigma_p_mk))
                    v_ls = (P_inv @ phi.T / sigma_n_mk
                            @ data[sids, dt_idx_x])
                    if ret_std:
                        ret_std_cov_4s[sids, :, idx_x] = np.sqrt(np.diag(P_inv))
                    elif ret_cov:
#                        b_cov = np.broadcast_to(P_inv, (len(sids), *P_inv.shape))
                        cov_mask = np.multiply.outer(alpha_mask, alpha_mask)
                        for sid in sids:
                            ret_std_cov_4s[sid, cov_mask, idx_x] = P_inv.flatten()
                else:
                    #v_ls, resid, rank, sigma = np.linalg.lstsq(
                    #    Phi, data[sids, idx_x], rcond=None) # LS - output
                    v_ls, _, _, _ = np.linalg.lstsq(phi, data[sids, dt_idx_x],
                                                    rcond=None) # LS - output
            elif len(n_tup) > 1:
                v_ls = np.ravel(data[0, dt_idx_x]/phi)
            else:
                v_ls = data[dt_idx_x]/phi
            tmp = np.zeros(p_max)
            tmp[alpha_mask] = v_ls
            ret_cf_ls_4s[sids, :, idx_x] = tmp
    return (ret_cf_ls_4s, ret_std_cov_4s) if ret_std or ret_cov else ret_cf_ls_4s

def gen_amrpc_dec_mk_ls(data, pol_vals, mk2sid, **kwargs):
    """
    computes the armpc-decomposition coefficients f_p of
    f(x,theta) = sum_p f_p(x) * pol_p(sample)
    on each multikey, mkey -> (p, x) by (pseudo inverse) least-squares

    Parameters
    ----------
    data : np.array[sample_id, space_point_nr]
        evaluations of f on samples theta for each space point x
    pol_vals : np.array[sample_id, pol_degree]
        eval of piecevise polynomials for each sample_id and pol_degree.
    mk2sid : dictionary
        MR-related multi-key -> sample id.
    kwargs:
        x_start: integer
            first space_point_nr to eval.
        x_len: integer
            length of the x-vector to eval, default x_len=-1
        method :  'pinv', 'pinvt', 'pinvth', 'ls'
            switches between least-squares and psedo-inverse based lsq

    Returns
    -------
    cf_ls_4mkeys: dictionary of np.arrays of f_i for mkey-> [p, x_i]

    """
    # compute function coefficients by least-squares
    # Fct coefs on each sample, (sid, p, x): by LS
    n_tup = data.shape
    if len(n_tup) > 1:
        n_x = n_tup[1]
    else:
        n_x = 1

    x_start = kwargs.get('x_start', 0)
    x_len = kwargs.get("x_len", n_x)
    x_len = n_x if x_len < 0 else x_len
    method = kwargs.get("method", 'pinv')
    if method in ('reg_n', 'reg_t'):
        sigma_n = kwargs.get('sigma_n', 1e-10)
        sigma_p = kwargs.get('sigma_p', 1)
    assert x_start + x_len <= n_x
    n_s = n_tup[0]
    p_max = pol_vals.shape[0]
    cf_ls_4mkeys = {}
    cf_ls_4mk = np.zeros((p_max, x_len))
    for mkey, sids in mk2sid.items():
        phi = pol_vals[:, sids].T
        for idx_x in range(x_len):
            # v, resid, rank, sigma = linalg.lstsq(A,y)
            # solves Av = y using least squares
            # sigma - singular values of A
            dt_idx_x = x_start + idx_x

            if n_s > 1:
                if method in ('pinv', 'reg'):
                    v_ls = np.linalg.pinv(phi) @ data[sids, dt_idx_x]
                elif method == 'pinvt':
                    v_ls = np.linalg.pinv(phi.T @ phi) @ phi.T @ data[sids, dt_idx_x]
                elif method == 'pinvth':
                    v_ls = (np.linalg.pinv(phi.T @ phi, hermitian=True)
                            @ phi.T @ data[sids, dt_idx_x])
                elif method == 'reg_n':
                    v_ls = (np.linalg.pinv(1/sigma_n * phi.T @ phi) @ phi.T / sigma_n
                            @ data[sids, dt_idx_x])
                elif method == 'reg_t':
                    P = (phi.T / sigma_n) @ phi + np.eye(phi.shape[1]) / sigma_p
                    v_ls = (np.linalg.pinv(P) @ phi.T / sigma_n
                            @ data[sids, dt_idx_x])
                else:
                    if n_s == len(sids):
                        v_ls, _, _, _ = np.linalg.lstsq(
                            phi, data[:, dt_idx_x], rcond=None) # LS - output
                    else:
                        #v_ls, resid, rank, sigma = np.linalg.lstsq(
                        #    Phi, data[sids, idx_x], rcond=None) # LS - output
                        v_ls, _, _, _ = np.linalg.lstsq(
                            phi, data[sids, dt_idx_x], rcond=None) # LS - output
            else:
                v_ls = data[dt_idx_x]/phi
            cf_ls_4mk[:, idx_x] = v_ls
        cf_ls_4mkeys[mkey] = cf_ls_4mk
    return cf_ls_4mkeys

def gen_amrpc_dec_q(data, pol_vals, mk2sid, weights):
    """
    computes the armpc-decomposition coefficients f_p of
    f(x,theta) = sum_p f_p(x) * pol_p(sample)
    on each sample, (sid, p, x) by using Gauss quadrature

    Parameters
    ----------
    data : np.array
        [sample_id, space_point_nr]
        evaluations of f on samples theta for each space point x.
    pol_vals : np.array
        np.array[sample_id, pol_degree]
        eval of picevise polynomials for each sample_id and pol_degree.
    mk2sid : dictionary
        MR-related multi-key -> sample id.
    weights : np.array
        Gaussian weights.

    Returns
    -------
    cf_q_4s : np.array
         f_i for [sid, p, x_i].

    """
    n_s, n_x = data.shape
    p_max = pol_vals.shape[0]
    cf_q_4s = np.zeros((n_s, p_max, n_x))
    weight_prod = np.prod(np.array(weights), axis=1)
    weighted_data = data.T * weight_prod # weighted samples
    #Fkt coefs.  on each sample, (sid, p, x) by quad

    for p in range(p_max):
        data_pol_4_p = weighted_data * pol_vals[p, :]
        for idx_x in range(n_x):
            for sids in mk2sid.values():
                if n_s > 1:
                    cf_q_4s[sids, p, idx_x] = sum(data_pol_4_p[idx_x, sids])
                else:
                    cf_q_4s[sids, p, idx_x] = data_pol_4_p[idx_x]
    return cf_q_4s
def cf_2_mean_var(cfs, rc_dict, mk2sid):
    """
    Computes mean and variance from the aMR-PC decompositions coeficients
    depending on type of cfs starts .._4s or _4mkey version of.

    Parameters
    ----------
    cfs : np.array
        [sample_id, pol_degree, x_idx], function coefs.
        or
        dictionary of np.array's
        mkey -> [pol_degree, x_idx], function coefs.
    rc_dict : dictionary
        (multi-key)->rescaling coefficent.
    mk2sid : dictionary
        (multi-key)->[sample_id].

    Returns
    -------
    mean : np.array
        expectation for all x.
    variance : np.array
        variance for all x.

    """
    if isinstance(cfs, dict):
        return cf_2_mean_var_4mkey(cfs, rc_dict)
    else:
        return cf_2_mean_var_4s(cfs, rc_dict, mk2sid)

def cf_2_mean_var_4s(cf_4s, rc_dict, mk2sid):
    """
    Computes mean and variance from the aMR-PC decompositions coeficients

    Parameters
    ----------
    cf_4s : np.array
        [sample_id, pol_degree, x_idx], function coefs.
    rc_dict : dictionary
        (multi-key)->rescaling coefficent.
    mk2sid : dictionary
        (multi-key)->[sample_id].

    Returns
    -------
    mean : np.array
        expectation for all x.
    variance : np.array
        variance for all x.

    """
    #_, p_max, n_x = cf_4s.shape
    tup = cf_4s.shape
    if len(tup) <= 2:
        n_x = 1
    else:
        n_x = tup[2]
    p_max = tup[1]
    mean = np.zeros(n_x)
    variance = np.zeros(n_x)
    for mkey, sids in mk2sid.items():
        sid = sids[0]  # first sample related to multi-key
        if n_x > 1:
            mean += cf_4s[sid, 0, :] * rc_dict[mkey]
            for p_d in range(p_max):
                variance += rc_dict[mkey] * (cf_4s[sid, p_d, :]**2)
        else:
            mean += cf_4s[sid, 0] * rc_dict[mkey]
            for p_d in range(p_max):
                variance += (cf_4s[sid, p_d]**2) *rc_dict[mkey]
    variance -= mean**2

    return mean, variance

def cf_2_mean_var_4mkey(cf_4mk, rc_dict):
    """
    Computes mean and variance from the aMR-PC decompositions coeficients

    Parameters
    ----------
    cf_4mk : dictionary of np.array's
        mkey -> [pol_degree, x_idx], function coefs.
    rc_dict : dictionary
        (multi-key)->rescaling coefficent.

    Returns
    -------
    mean : np.array
        expectation for all x.
    variance : np.array
        variance for all x.

    """
    #_, p_max, n_x = cf_4s.shape
    n_x = 0

    for mkey, cfs in cf_4mk.items():
        if n_x == 0:
            tup = cfs.shape
            if len(tup) < 2:
                n_x = 1
            else:
                n_x = tup[1]
            p_max = tup[0]
            mean = np.zeros(n_x)
            variance = np.zeros(n_x)
        if n_x > 1:
            mean += cfs[0, :] * rc_dict[mkey]
            for p_d in range(p_max):
                variance += rc_dict[mkey] * (cfs[p_d, :]**2)
        else:
            mean += cfs[0] * rc_dict[mkey]
            for p_d in range(p_max):
                variance += (cfs[p_d]**2) *rc_dict[mkey]
    variance -= mean**2

    return mean, variance


def add_samples(samples, new_samples):
    """
    Adds new samples to the samples np.array

    Parameters
    ----------
    samples : np.array
        old samples.
    new_samples : np.array
        new samples.

    Returns
    -------
    TYPE
        np.array.

    """
    sdim = samples.shape[1]
    n_dim = new_samples.shape[1]
    assert sdim == n_dim
    return np.concatenate((samples, new_samples), axis=0)

def update_mk2sid_samples(new_samples, start_sid, nrb_dict, mk_list, mk2sid, sid2mk):
    """
    updates multikey->sample id dictionary for new samples

    Parameters
    ----------
    new_samples : np.array
        array of new_samples.
    start_sid : int
        sample id, which should be related to the first sample.
    nrb_dict : dictionary
        dictionary of element bounaries.
    mk_list : list
        list of multi-keys (touples of touples).
    mk2sid : dictionary
        old multi-key- > sid dictionary.
    sid2mk : dictionary
        old sample id -> multi-key dictionary.

    Returns
    -------
    sid2mk : dictionary
        updatet sample id -> multi-key dictionary.
    mk2sid : dictionary
        updated multi-key -> sample id dictionary.
    new_mk2sid : dictionary
        multi-key -> sample id dictionary of new_new samples only.

    """
    new_samples_cnt = new_samples.shape[0]
    sids = np.arange(new_samples_cnt) + start_sid
    new_mk2sid = {}
    mk2sid_u = mk2sid.copy()
    sid2mk_u = sid2mk.copy()
    for mkey in mk_list:
        b_msk = cmp_mv_quant_domain_mk(new_samples, nrb_dict, mkey)
        new_mk2sid[mkey] = sids[b_msk]
        if mkey in mk2sid_u:
            mk2sid_u[mkey] = np.concatenate((mk2sid_u[mkey], sids[b_msk]), axis=0)
        else:
            mk2sid_u[mkey] = sids[b_msk]
        for sid in sids[b_msk]:
            if sid in sid2mk_u:
                sid2mk_u[sid] += mkey
            else:
                sid2mk_u[sid] = [mkey]
    return sid2mk_u, mk2sid_u, new_mk2sid

def update_pol_vals_on_samples(samples_updated, new_samples_cnt, pol_vals, npc_dict,
                               alphas, new_mk2sid):
    """
    Updates polynomial values after update of the samples

    Parameters
    ----------
    samples_updated : np.array
        array of samples after update.
    new_samples_cnt : int
        number of new samples.
    pol_vals : np.array
        pol_vals computed before update of samples.
    npc_dict : dictionary
        dictionary of polynomial coeficients.
    alphas : np.array
        degrees of multivariate polynomials.
    new_mk2sid : dictionary
        multikey->sample_id dictionary for new samples only.

    Returns
    -------
    pol_vals : np.array
        values of polynomials on samples_updated.

    """

    p_max = alphas.shape[0]
    pol_vals = np.concatenate((pol_vals, np.zeros((p_max, new_samples_cnt))),
                              axis=1)

    for mkey in new_mk2sid:
        sids = new_mk2sid[mkey]
        for idx_p in range(p_max):
            pcfs = pcfs4eval(npc_dict, mkey, alphas[idx_p])
            pvals = pt.pc_eval(pcfs, samples_updated[sids, :])
            pol_vals[idx_p, sids] = np.prod(pvals, axis=1)
    return pol_vals

def main():
    """ some tests """
    # data location
#    url = '../data/InputParameters.txt'

#    # load data
#    dataframe = pd.read_csv(url, header=None, sep='\s+ ', engine='python')
#    n_r = 2
#    nr_range = np.arange(n_r+1)
#    n_o = 2
#    srcs = np.arange(0, 1)
#    method = 0
#    h_dict = genHankel(dataframe, srcs, nr_range, n_o)
#    print(h_dict)
#    # further with test004
#    roots, weights = gen_roots_weights(h_dict, method)
#    print(roots, weights)
